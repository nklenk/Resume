{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent\n",
    "\n",
    "Creating a linear regression to explore gradient descent using sklearn\n",
    "Using infomation about PGA players didtance and accuracy which can be found in the \"Data\" folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pga = pd.read_csv(\"/Users/neilklenk/Documents/Datasets/pga.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalizing the data, so that it is all on the same scale. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pga.distance = (pga.distance - pga.distance.mean())/pga.distance.std()\n",
    "pga.accuracy = (pga.accuracy - pga.accuracy.mean())/pga.accuracy.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to determint the cost for a single variable for the linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cost(theta0, theta1, x, y):\n",
    "    \n",
    "    J=0\n",
    "    # The number of observations\n",
    "    m = len(x)\n",
    "    # Loop through each observation\n",
    "    for i in range(m):\n",
    "        # Compute the hypothesis \n",
    "        h = theta1 * x[i] + theta0\n",
    "        # Add to cost\n",
    "        J += (h - y[i])**2\n",
    "    # Average and normalize cost\n",
    "    J /= (2*m)\n",
    "    return J"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the partial derivative of the cost to determine in which direction to update the values so that the cost is reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partial_cost_theta1(theta0, theta1, x, y):\n",
    "    # Hypothesis\n",
    "    h = theta0 + theta1*x\n",
    "    # Hypothesis minus observed times x\n",
    "    diff = (h - y) * x\n",
    "    # Average to compute partial derivative\n",
    "    partial = diff.sum() / (x.shape[0])\n",
    "    return partial\n",
    "\n",
    "def partial_cost_theta0(theta0, theta1, x, y):\n",
    "    h = theta0 + theta1*x\n",
    "    diff = h - y \n",
    "    partial = diff.sum() / (x.shape[0])\n",
    "    return partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient descent algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv degree: 0.0349269661155\n",
      "Conv degree: 0.0283226032499\n",
      "Conv degree: 0.022967063678\n",
      "Conv degree: 0.0186242065863\n",
      "Conv degree: 0.0151025431824\n",
      "Conv degree: 0.0122467934148\n",
      "Conv degree: 0.00993103923838\n",
      "Conv degree: 0.00805317253375\n",
      "Conv degree: 0.00653039287245\n",
      "Conv degree: 0.00529555661322\n",
      "Conv degree: 0.00429421634985\n",
      "Conv degree: 0.00348222017178\n",
      "Conv degree: 0.00282376488207\n",
      "Conv degree: 0.00228981733374\n",
      "Conv degree: 0.00185683427653\n",
      "Conv degree: 0.00150572426878\n",
      "Conv degree: 0.00122100588203\n",
      "Conv degree: 0.000990125081241\n",
      "Conv degree: 0.000802901682073\n",
      "Conv degree: 0.0006510804779\n",
      "Conv degree: 0.000527967244518\n",
      "Conv degree: 0.000428133572953\n",
      "Conv degree: 0.000347177515638\n",
      "Conv degree: 0.000281529492147\n",
      "Conv degree: 0.000228294896352\n",
      "Conv degree: 0.000185126465093\n",
      "Conv degree: 0.000150120780733\n",
      "Conv degree: 0.000121734344123\n",
      "Conv degree: 9.87155173766e-05\n",
      "Conv degree: 8.00493356345e-05\n",
      "Conv degree: 6.4912754406e-05\n",
      "Conv degree: 5.26383592211e-05\n",
      "Conv degree: 4.268493745e-05\n",
      "Conv degree: 3.46136147112e-05\n",
      "Conv degree: 2.8068503667e-05\n",
      "Conv degree: 2.2761011952e-05\n",
      "Conv degree: 1.84571173155e-05\n",
      "Conv degree: 1.49670489313e-05\n",
      "Conv degree: 1.21369198601e-05\n",
      "Conv degree: 9.8419417463e-06\n",
      "Conv degree: 7.98092254461e-06\n",
      "Conv degree: 6.471804681e-06\n",
      "Conv degree: 5.24804690116e-06\n",
      "Conv degree: 4.25569028034e-06\n",
      "Conv degree: 3.45097902182e-06\n",
      "Conv degree: 2.79843114165e-06\n",
      "Conv degree: 2.26927396707e-06\n",
      "Conv degree: 1.84017546823e-06\n",
      "Conv degree: 1.49221548573e-06\n",
      "Conv degree: 1.21005148329e-06\n",
      "Conv degree: 9.81242057219e-07\n",
      "Theta1 = -0.6064318711932262\n"
     ]
    }
   ],
   "source": [
    "def gradient_descent(x, y, alpha=0.1, theta0=0, theta1=0):\n",
    "    max_epochs = 1000 # Maximum number of iterations\n",
    "    counter = 0      \n",
    "    c = cost(theta1, theta0, pga.distance, pga.accuracy)  ## Initial cost\n",
    "    costs = [c]     \n",
    "    # Set a convergence threshold to prevent the program from running after it converges\n",
    "    convergence_thres = 0.000001  \n",
    "    cprev = c + 10   \n",
    "    theta0s = [theta0]\n",
    "    theta1s = [theta1]\n",
    "\n",
    "    # When the costs converge or we hit a large number of iterations will we stop updating\n",
    "    while (np.abs(cprev - c) > convergence_thres) and (counter < max_epochs):\n",
    "        cprev = c\n",
    "        # learning rate detemines the size of step we take once the direction (partial deriviative) is determined\n",
    "        update0 = alpha * partial_cost_theta0(theta0, theta1, x, y)\n",
    "        update1 = alpha * partial_cost_theta1(theta0, theta1, x, y)\n",
    "\n",
    "        # Update theta0 and theta1 at the same time to compute the slopes at the same set\n",
    "        # of hypothesised parameters. Update adter finding the partial derivaives\n",
    "        theta0 -= update0\n",
    "        theta1 -= update1\n",
    "        \n",
    "        # Store thetas\n",
    "        theta0s.append(theta0)\n",
    "        theta1s.append(theta1)\n",
    "        \n",
    "        # Compute the new cost\n",
    "        c = cost(theta0, theta1, pga.distance, pga.accuracy)\n",
    "\n",
    "        # Store updates\n",
    "        costs.append(c)\n",
    "        counter += 1   # Count\n",
    "        print(\"Conv degree:\", np.abs(cprev - c))\n",
    "\n",
    "    return {'theta0': theta0, 'theta1': theta1, \"costs\": costs}\n",
    "\n",
    "print(\"Theta1 =\", gradient_descent(pga.distance, pga.accuracy)['theta1'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv degree: 0.0349269661155\n",
      "Conv degree: 0.0283226032499\n",
      "Conv degree: 0.022967063678\n",
      "Conv degree: 0.0186242065863\n",
      "Conv degree: 0.0151025431824\n",
      "Conv degree: 0.0122467934148\n",
      "Conv degree: 0.00993103923838\n",
      "Conv degree: 0.00805317253375\n",
      "Conv degree: 0.00653039287245\n",
      "Conv degree: 0.00529555661322\n",
      "Conv degree: 0.00429421634985\n",
      "Conv degree: 0.00348222017178\n",
      "Conv degree: 0.00282376488207\n",
      "Conv degree: 0.00228981733374\n",
      "Conv degree: 0.00185683427653\n",
      "Conv degree: 0.00150572426878\n",
      "Conv degree: 0.00122100588203\n",
      "Conv degree: 0.000990125081241\n",
      "Conv degree: 0.000802901682073\n",
      "Conv degree: 0.0006510804779\n",
      "Conv degree: 0.000527967244518\n",
      "Conv degree: 0.000428133572953\n",
      "Conv degree: 0.000347177515638\n",
      "Conv degree: 0.000281529492147\n",
      "Conv degree: 0.000228294896352\n",
      "Conv degree: 0.000185126465093\n",
      "Conv degree: 0.000150120780733\n",
      "Conv degree: 0.000121734344123\n",
      "Conv degree: 9.87155173766e-05\n",
      "Conv degree: 8.00493356345e-05\n",
      "Conv degree: 6.4912754406e-05\n",
      "Conv degree: 5.26383592211e-05\n",
      "Conv degree: 4.268493745e-05\n",
      "Conv degree: 3.46136147112e-05\n",
      "Conv degree: 2.8068503667e-05\n",
      "Conv degree: 2.2761011952e-05\n",
      "Conv degree: 1.84571173155e-05\n",
      "Conv degree: 1.49670489313e-05\n",
      "Conv degree: 1.21369198601e-05\n",
      "Conv degree: 9.8419417463e-06\n",
      "Conv degree: 7.98092254461e-06\n",
      "Conv degree: 6.471804681e-06\n",
      "Conv degree: 5.24804690116e-06\n",
      "Conv degree: 4.25569028034e-06\n",
      "Conv degree: 3.45097902182e-06\n",
      "Conv degree: 2.79843114165e-06\n",
      "Conv degree: 2.26927396707e-06\n",
      "Conv degree: 1.84017546823e-06\n",
      "Conv degree: 1.49221548573e-06\n",
      "Conv degree: 1.21005148329e-06\n",
      "Conv degree: 9.81242057219e-07\n"
     ]
    }
   ],
   "source": [
    "grad_descent = gradient_descent(pga.distance, pga.accuracy, alpha = 0.1)\n",
    "x = [i for i in range(0,len(grad_descent['costs']))]\n",
    "y = grad_descent['costs']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the results of our gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEWCAYAAAB1xKBvAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKNwHS92gAAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x118752f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y)\n",
    "plt.title(\"Changing function cost during gradient descent\")\n",
    "plt.xlabel(\"Iteration Number\")\n",
    "plt.ylabel(\"Cost\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
